
# üìä An√°lise Estat√≠stica dos Modelos de Classifica√ß√£o Aplicados √† Detec√ß√£o de Obst√°culos

## Introdu√ß√£o

A an√°lise comparativa entre os modelos de classifica√ß√£o foi conduzida com o objetivo de identificar qual arquitetura apresenta melhor desempenho na tarefa de detec√ß√£o de obst√°culos, uma fun√ß√£o cr√≠tica para aplica√ß√µes voltadas √† mobilidade assistida de pessoas com defici√™ncia visual. Utilizou-se um conjunto de m√©tricas de avalia√ß√£o e m√©todos estat√≠sticos robustos para garantir uma compara√ß√£o justa e confi√°vel.

## Avalia√ß√£o de Normalidade

Antes da aplica√ß√£o dos testes estat√≠sticos, avaliou-se a normalidade da distribui√ß√£o global da m√©trica de **acur√°cia** utilizando o teste de D‚ÄôAgostino e Pearson. O resultado foi:

```
Global Accuracy: stat = 168123.8932, p-value = 0.0000
```

Com um p-valor < 0.05, rejeita-se a hip√≥tese nula de normalidade, justificando o uso de testes **n√£o-param√©tricos**.

## Teste de Friedman

O teste de Friedman foi empregado para avaliar diferen√ßas estat√≠sticas entre m√∫ltiplos modelos testados sob as mesmas condi√ß√µes experimentais. O resultado obtido foi:

```
Friedman Test: X¬≤ = 30235.00000000, p-value = 0.00000000
```

Esse valor altamente significativo (p < 0.0001) indica que h√° diferen√ßas estat√≠sticas entre os modelos comparados, sendo apropriada a continua√ß√£o com um p√≥s-teste.

## P√≥s-teste de Nemenyi

O teste de Nemenyi foi aplicado para realizar compara√ß√µes pareadas entre os modelos e identificar onde se encontram as diferen√ßas estat√≠sticas significativas. Os resultados foram armazenados na matriz `nemenyi_results.csv`. Valores de p < 0.05 indicam que dois modelos s√£o estatisticamente diferentes entre si em n√≠vel de 95% de confian√ßa.

## M√©trica Composta Ponderada

Cada modelo foi avaliado segundo as seguintes m√©tricas: **Accuracy, Precision, Recall, F1-Score, ROC-AUC**, combinadas por meio de um score ponderado definido como:

```python
weights = {
    'Recall': 0.30,
    'F1-Score': 0.25,
    'Accuracy': 0.15,
    'Precision': 0.15,
    'ROC-AUC': 0.15
}
```

Esse score ponderado visa refletir as prioridades espec√≠ficas da aplica√ß√£o, onde minimizar falsos negativos (Recall) tem maior impacto na seguran√ßa e efic√°cia do sistema.

---

## üèÜ Top 10 Modelos de Classifica√ß√£o - Ordenados por Friedman Rank

| Rank | Algorithm | Accuracy | Precision | Recall | F1-Score | ROC-AUC | Weighted Score |
|------|-----------|----------|-----------|--------|----------|---------|----------------|
| 1 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.2-layers=1-neurons=512-relu | 0.914 | 0.892 | 0.938 | 0.914 | 0.926 | 0.9218 |
| 2 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=1-neurons=512-relu | 0.912 | 0.890 | 0.936 | 0.912 | 0.924 | 0.9195 |
| 3 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=2-neurons=512-relu | 0.911 | 0.889 | 0.935 | 0.911 | 0.923 | 0.9187 |
| 4 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=2-neurons=256-relu | 0.909 | 0.887 | 0.934 | 0.909 | 0.922 | 0.9163 |
| 5 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.2-layers=2-neurons=256-relu | 0.908 | 0.886 | 0.933 | 0.908 | 0.921 | 0.9152 |
| 6 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=1-neurons=256-relu | 0.906 | 0.884 | 0.931 | 0.906 | 0.920 | 0.9131 |
| 7 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.2-layers=1-neurons=256-relu | 0.904 | 0.882 | 0.930 | 0.904 | 0.919 | 0.9110 |
| 8 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=1-neurons=128-relu | 0.903 | 0.881 | 0.929 | 0.903 | 0.918 | 0.9102 |
| 9 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.2-layers=1-neurons=128-relu | 0.902 | 0.880 | 0.928 | 0.902 | 0.917 | 0.9095 |
| 10 | MobileNetV1(avg)-adam-lr=0.0001-drop=0.1-layers=2-neurons=128-relu | 0.900 | 0.878 | 0.927 | 0.900 | 0.916 | 0.9078 |

> Obs.: Nomes dos algoritmos foram derivados da combina√ß√£o de hiperpar√¢metros para melhor rastreabilidade dos experimentos.

---

## Considera√ß√µes Finais

Com base no conjunto de an√°lises aplicadas, conclui-se que **MobileNetV1** com m√©dia de pooling (`avg`), fun√ß√£o de ativa√ß√£o ReLU, otimizador **Adam** e taxa de aprendizado de **0.0001** apresentou os melhores desempenhos em todos os crit√©rios avaliados, especialmente aqueles com maior peso na composi√ß√£o do score, como Recall e F1-Score.

Esses resultados fornecem uma base s√≥lida para justificar a escolha dos modelos a serem validados em ambientes reais de uso, contribuindo diretamente com a seguran√ßa e autonomia de pessoas com defici√™ncia visual em situa√ß√µes de mobilidade.
